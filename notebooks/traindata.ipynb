{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"quality_evaluation_data.xlsx\"\n",
    "df_e = pd.read_excel(file_path, sheet_name='error_samples')\n",
    "df_n = pd.read_excel(file_path, sheet_name='normal_samples')\n",
    "err_columns = ['table', 'col_nm', 'domain', 'rule', 'total_cnt', 'err_cnt', 'err_rt', 'err_ext_sql',\n",
    "       'err_data']\n",
    "nor_columns = ['table', 'col_nm', 'datatype', 'rule', 'domain', 'verify_type', 'err_free_data', 'act_date',\n",
    "       'nornal_data', 'others']\n",
    "df_e.columns = err_columns\n",
    "df_n.columns = nor_columns\n",
    "df = df_n.merge(df_e, 'left', on=['table','col_nm'])\n",
    "df = df[['table', 'col_nm', 'domain_x', 'nornal_data', 'err_data', 'datatype', 'rule_x',  'total_cnt', 'err_cnt', 'err_rt']]\n",
    "df =df.rename(columns={'nornal_data':'normal_data', 'rule_x':'rule', 'domain_x':'domain'})\n",
    "df = df[~df.normal_data.isna()]\n",
    "df = df.assign(normal_data = df.normal_data.str.split(',').astype('str'),\n",
    "             err_data = df.err_data.str.split(',').astype('str'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_feature.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pandas import Series\n",
    "\n",
    "\n",
    "class BuildFeatures():\n",
    "    \"\"\"\n",
    "    ## 전처리\n",
    "    - None, NULL 등의 갯수/비율 체크 및 삭제\n",
    "    ##전체패턴\n",
    "    - 날짜 형식 비율 \n",
    "    - 숫자 비율(실수, 정수, 00012같은 것은 걸려낼 것)\n",
    "    - 정수 비율\n",
    "    - 번호패턴 비율\n",
    "    - 문자번호패턴 비율 \n",
    "    - 이메일 비율\n",
    "    - URL 비율\n",
    "    ##부분패턴\n",
    "    - 숫자포함\n",
    "    - 문자포함(한글영문)\n",
    "    - discriminator포함\n",
    "    - masking포함\n",
    "    - 음수포함\n",
    "    ## 데이터 속성\n",
    "    - 데이터길이 Purity : 0~1, 1에 가까울수록 고정길이, (엔트로피를 사용해도 될 듯)\n",
    "    - 데이터 Distinct 수\n",
    "    - 데이터 엔트로피 : distinct 값의 분포. Noise로 인한 distinct가 크면 의미가 있는데, 계산량이 많이 들 수 있다.\n",
    "    ##메타데이터\n",
    "    - 컬럼도메인: 컬럼명으로부터 도메인 접미사 추출하여 해당도메인 onehot처리(도메인별 접미사 구성)\n",
    "    - 데이터 타입\n",
    "    \n",
    "    # usage\n",
    "        data = {\n",
    "            'sample_column': [\n",
    "                '2023-01-01', '100', '300.5', 'test@example.com', 'http://example.com', \n",
    "                '2023-02-01', '200', '400.5', 'hello@world.com', 'https://world.com',\n",
    "                '2023-03-01', 'NULL', None, 'NaN', '2023-04-01'\n",
    "            ]\n",
    "        }\n",
    "        # 판다스 데이터프레임 생성\n",
    "        df = pd.DataFrame(data)\n",
    "        # BuildFeatures 클래스 인스턴스화\n",
    "        bf = BuildFeatures(df['sample_column'], 'SAMPLE_sz')\n",
    "        # 프로파일링 패턴 호출\n",
    "        profile = bf.profiling_patterns()\n",
    "        print(profile)    \n",
    "            \n",
    "    \"\"\"\n",
    "    YYYY = r\"(19|20)\\d{2}\"\n",
    "    MM = r\"(0[1-9]|1[012])\"\n",
    "    DD = r\"(0[1-9]|[12][0-9]|3[01])\"\n",
    "    TM = r\"\\s+([01][0-9]|2[0-4]):[0-5][0-9](:[0-5][0-9])?(\\s+(PM|AM))?\"\n",
    "    patterns = {\n",
    "        \"date_time\": fr\"^({YYYY}[-./]{MM}[-./]{DD}|{MM}[-./]{DD}[-./]{YYYY}|{DD}[-./]{MM}[-./]{YYYY})({TM})?$\",\n",
    "        \"number\": r\"^(?!0\\d)\\d+([.]\\d*)?$\",\n",
    "        \"integer\": r\"^(?!0\\d)\\d+$\",\n",
    "        \"bunho\": r\"^[A-Za-z0-9\\uAC00-\\uD7A3]+([-./:][A-Za-z0-9\\uAC00-\\uD7A3]+)*$\",\n",
    "        \"email\": r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\",\n",
    "        \"url\": r\"^(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)*\\/?$\",\n",
    "        \"part_num\": r\"\\d+\",\n",
    "        \"part_text\": r\"[A-Za-z\\uAC00-\\uD7A3]+\",\n",
    "        \"part_discriminator\": r\"[./-:]\",\n",
    "        \"part_mask\": r\"[#*]{3,}\",\n",
    "        \"part_minus\": r\"^-\\d\",\n",
    "    }\n",
    "\n",
    "    #  도메인 접미사 패턴 그룹 정의 및 결합\n",
    "    suffix_patterns = {\n",
    "        \"BUNHO\": \"(?P<BUNHO>(NO|SN|ZIP|TKN|VIN|ENTN)$)\",\n",
    "        \"NALJJA\": \"(?P<NALJJA>(DT|YMD|YM|YR|SYR|MM|DAY)$)\",\n",
    "        \"MYEONG\": \"(?P<MYEONG>(NM|TTL)$)\",\n",
    "        \"JUSO\": \"(?P<JUSO>(ADDR)$)\",\n",
    "        \"YEOBU\": \"(?P<YEOBU>YN$)\",\n",
    "        \"CODE\": \"(?P<CODE>CD$)\",\n",
    "        \"ID\": \"(?P<ID>ID$)\",\n",
    "        \"SURYANG\": \"(?P<SURYANG>(LOT|DONT|GRD|LVL|GFA|AREA|PRG|SCR|CNT|LEN|SZ)$)\",\n",
    "        \"GEUMAEK\": \"(?P<GEUMAEK>(AMT|FEE|UNTPRC)$)\",\n",
    "        \"NAEYOUNG\": \"(?P<NAEYOUNG>CN$)\",\n",
    "        \"YUL\": \"(?P<YUL>RT$)\",\n",
    "    }\n",
    "    combined_pattern = re.compile(\"|\".join(suffix_patterns.values()),  re.IGNORECASE)\n",
    "    \n",
    "    def __init__(self, series:Series, col_name:str=None):\n",
    "        if not isinstance(series, pd.Series):\n",
    "            raise ValueError(\"series must be a pandas Series\")        \n",
    "        \n",
    "        na_rate = series.isna().mean()\n",
    "        null_rate = series.str.strip().isin(['NULL', 'NaN']).mean()\n",
    "        \n",
    "        self.null_rate = na_rate + null_rate\n",
    "        self.series = series[~series.isin(['NULL', 'NaN'])].dropna()\n",
    "        self.datatype = self.series.dtype.name  \n",
    "        self.col_name = col_name if col_name else self.series.name\n",
    "\n",
    "        # self.patterns = patterns\n",
    "        \n",
    "    def rate_matching_pattern(self, pattern:str)-> float:\n",
    "        # series = self.series.dropna()\n",
    "        return self.series.str.contains(pattern, regex=True).mean()\n",
    "    \n",
    "\n",
    "    def get_length_purity(self)-> float:\n",
    "        # series = self.series.dropna().astype(str)\n",
    "        ratio = self.series.str.len().value_counts(normalize=True)\n",
    "        length_purity = (ratio * ratio).sum()\n",
    "        return length_purity\n",
    "    \n",
    "    def get_value_nunique(self):\n",
    "        return self.series.nunique()\n",
    "        # self.series.value_counts()\n",
    "        \n",
    "    def get_value_distr(self):\n",
    "        ratio = self.series.value_counts(normalize=True)\n",
    "        entropy = (-ratio * np.log2(ratio)).sum()\n",
    "        return entropy\n",
    "    \n",
    "    def find_suffix_domain(self):\n",
    "        \"\"\"\n",
    "        컬럼명에서 도메인분류어 패턴을 추출하여 어떤 도메인그룹의 suffix에 해당하는지 검출\n",
    "        :return: 매칭된 그룹 이름 또는 '해당 사항 없음'\n",
    "        \"\"\"\n",
    "        word = self.col_name\n",
    "        if not isinstance(word, str) or not word:\n",
    "            return \"유효하지 않은 입력\"\n",
    "        \n",
    "        match = self.combined_pattern.search(word)\n",
    "        if match:\n",
    "            matched_groups = [name for name, value in match.groupdict().items() if value]\n",
    "            return matched_groups if matched_groups else \"ETC\"\n",
    "        else:\n",
    "            return \"ETC\"\n",
    "           \n",
    "    def one_hot_encode(self, domain:str, categories: list) -> dict:\n",
    "       \"\"\"\n",
    "       주어진 pandas Series를 one-hot 인코딩으로 변환합니다.\n",
    "    \n",
    "       :param series: 인코딩할 pandas Series 객체\n",
    "       :param categories: one-hot 인코딩을 위한 카테고리 리스트\n",
    "       :return: 카테고리 값을 키로 하고 one-hot 인코딩된 pd.Series를 값으로 하는 딕셔너리\n",
    "       \"\"\"\n",
    "       if not isinstance(categories, list):\n",
    "           categories = list(categories)\n",
    "       categories = categories +['ETC'] # categories에 들어가지 않는 것은 ETC로 추가로 분류한다.\n",
    "       one_hot_encoded = pd.get_dummies(domain, prefix='', prefix_sep='').reindex(columns=categories, fill_value=0)\n",
    "       return one_hot_encoded.iloc[0].to_dict() \n",
    "\n",
    "    def profiling_patterns(self)-> Series:\n",
    "        features = {}\n",
    "        for key, pattern in self.patterns.items():\n",
    "            features[key] = self.rate_matching_pattern(pattern)\n",
    "        features['len_purity'] = self.get_length_purity()\n",
    "        features['value_nunique'] = self.get_value_nunique()\n",
    "        features['value_distr'] = self.get_value_distr()\n",
    "        features['datatype'] = self.datatype\n",
    "        suffix_domain = self.find_suffix_domain()\n",
    "        one_hot_encoded = self.one_hot_encode(suffix_domain, self.suffix_patterns.keys()) \n",
    "        features = {**features, **one_hot_encoded}\n",
    "        \n",
    "        return pd.Series(features,name = self.col_name )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use_case\n",
    "data = {\n",
    "    'sample_column': [\n",
    "        '2023-01-01', '100', '300.5', 'test@example.com', 'http://example.com', \n",
    "        '2023-02-01', '200', '400.5', 'hello@world.com', 'https://world.com',\n",
    "        '2023-03-01', 'NULL', None, 'NaN', '2023-04-01'\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "\n",
    "    'ENTN': [\n",
    "        '200905830','201785062','080146287','200100957','201810936'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 판다스 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "# BuildFeatures 클래스 인스턴스화\n",
    "bf = BuildFeatures(df['ENTN'], 'ENTN')\n",
    "# 프로파일링 패턴 호출\n",
    "profile = bf.profiling_patterns()\n",
    "print(profile)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['080068544', '080134675', '080135855', '080139164', '080147596']\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.normal_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2series(str_list):\n",
    "    return pd.Series(eval(str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['table', 'col_nm', 'domain', 'normal_data', 'err_data', 'datatype',\n",
       "       'rule', 'total_cnt', 'err_cnt', 'err_rt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n",
      "/tmp/ipykernel_4616/930959982.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return self.series.str.contains(pattern, regex=True).mean()\n"
     ]
    }
   ],
   "source": [
    "profiles =[]\n",
    "for row in df[:10].itertuples():\n",
    "    series = str2series(row.normal_data)\n",
    "    series.name = row.col_nm\n",
    "    profile = BuildFeatures(series).profiling_patterns()\n",
    "    profiles.append(profile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>number</th>\n",
       "      <th>integer</th>\n",
       "      <th>bunho</th>\n",
       "      <th>email</th>\n",
       "      <th>url</th>\n",
       "      <th>part_num</th>\n",
       "      <th>part_text</th>\n",
       "      <th>part_discriminator</th>\n",
       "      <th>part_mask</th>\n",
       "      <th>...</th>\n",
       "      <th>MYEONG</th>\n",
       "      <th>JUSO</th>\n",
       "      <th>YEOBU</th>\n",
       "      <th>CODE</th>\n",
       "      <th>ID</th>\n",
       "      <th>SURYANG</th>\n",
       "      <th>GEUMAEK</th>\n",
       "      <th>NAEYOUNG</th>\n",
       "      <th>YUL</th>\n",
       "      <th>ETC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENTN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PWD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USNA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPR_GIVE_DATE</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPER_GIVE_DATE</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPER_GIVE_NAME</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUSN_REGN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  number  integer  bunho  email  url  part_num  \\\n",
       "ENTN                  0.0    0.00     0.00    1.0    0.0  0.0       1.0   \n",
       "GRADE                 0.0    1.00     1.00    1.0    0.0  0.0       1.0   \n",
       "PWD                   0.0    0.80     0.80    1.0    0.0  0.0       1.0   \n",
       "USNA                  0.0    0.00     0.00    1.0    0.0  0.0       0.0   \n",
       "APPR_GIVE_DATE        1.0    0.00     0.00    0.0    0.0  0.0       1.0   \n",
       "OPER_GIVE_DATE        1.0    0.00     0.00    0.0    0.0  0.0       1.0   \n",
       "OPER_GIVE_NAME        0.0    0.00     0.00    1.0    0.0  0.0       0.0   \n",
       "BUSN_REGN             0.0    0.75     0.75    1.0    0.0  0.0       1.0   \n",
       "ENTN                  0.0    0.80     0.80    1.0    0.0  0.0       1.0   \n",
       "GRADE                 0.0    1.00     1.00    1.0    0.0  0.0       1.0   \n",
       "\n",
       "                part_text  part_discriminator  part_mask  ...  MYEONG  JUSO  \\\n",
       "ENTN                  0.0                 1.0        0.0  ...       0     0   \n",
       "GRADE                 0.0                 1.0        0.0  ...       0     0   \n",
       "PWD                   0.0                 1.0        0.0  ...       0     0   \n",
       "USNA                  1.0                 0.0        0.0  ...       0     0   \n",
       "APPR_GIVE_DATE        0.0                 1.0        0.0  ...       0     0   \n",
       "OPER_GIVE_DATE        0.0                 1.0        0.0  ...       0     0   \n",
       "OPER_GIVE_NAME        1.0                 0.0        0.0  ...       0     0   \n",
       "BUSN_REGN             0.0                 1.0        0.0  ...       0     0   \n",
       "ENTN                  0.0                 1.0        0.0  ...       0     0   \n",
       "GRADE                 0.0                 1.0        0.0  ...       0     0   \n",
       "\n",
       "                YEOBU  CODE ID SURYANG  GEUMAEK  NAEYOUNG  YUL   ETC  \n",
       "ENTN                0     0  0       0        0         0    0     0  \n",
       "GRADE               0     0  0       0        0         0    0  True  \n",
       "PWD                 0     0  0       0        0         0    0  True  \n",
       "USNA                0     0  0       0        0         0    0  True  \n",
       "APPR_GIVE_DATE      0     0  0       0        0         0    0  True  \n",
       "OPER_GIVE_DATE      0     0  0       0        0         0    0  True  \n",
       "OPER_GIVE_NAME      0     0  0       0        0         0    0  True  \n",
       "BUSN_REGN           0     0  0       0        0         0    0  True  \n",
       "ENTN                0     0  0       0        0         0    0     0  \n",
       "GRADE               0     0  0       0        0         0    0  True  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                         080068544,080134675,080135855,080139164,080147596\n",
       "1                                                                                                       1,2\n",
       "2                                                                                  0000,1234,1111,7168,1004\n",
       "3                                                                                       담당자,김주희,정경민,김가영,이정희\n",
       "4       2018-10-16 17:04:54,2019-07-15 14:10:07,2008-09-25 13:41:09,2008-09-26 15:21:20,2008-10-13 17:27:52\n",
       "                                                       ...                                                 \n",
       "2237                                                                      NULL,20180068,-,19910022,19960081\n",
       "2239                                                                         NULL,자원순환지원부,청소행정과,환경관리과,자원순환과\n",
       "2240                                                             NULL,1644-0007,02-3153-0514,-,031-590-0620\n",
       "2241                                                                                    000,901,909,902,905\n",
       "2242                                                                                    000,901,909,902,905\n",
       "Name: normal_data, Length: 1959, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.normal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             ['080068544', '080134675', '080135855', '080139164', '080147596']\n",
       "2                                                      ['0000', '1234', '1111', '7168', '1004']\n",
       "7                              ['NULL', '0000000000', '1208200052', '3068200471', '6138300022']\n",
       "8                             ['131037196', '080146287', '200022389', '200100957', '202211277']\n",
       "10                ['031-634-1762', '0629538902', '0319723084', '043-750-7395', '010-2542-4407']\n",
       "                                                 ...                                           \n",
       "2216                                                              ['NULL', '2', '3', '6', '10']\n",
       "2231    ['210.99.81.253', '210.99.81.254', '210.99.81.251', '210.104.107.34', '210.104.107.50']\n",
       "2233                          ['200305241', '200309912', '200311019', '200412103', '200418018']\n",
       "2237                                          ['NULL', '20180068', '-', '19910022', '19960081']\n",
       "2240                                 ['NULL', '1644-0007', '02-3153-0514', '-', '031-590-0620']\n",
       "Name: normal_data, Length: 441, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max.colwidth', None)\n",
    "df.query('domain == \"번호\"')['normal_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['080068544', '080134675', '080135855', '080139164', '080147596']\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.normal_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
